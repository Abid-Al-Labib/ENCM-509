{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.1-cp39-cp39-win_amd64.whl (7.6 MB)\n",
      "     ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.8/7.6 MB 24.1 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 1.8/7.6 MB 22.4 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 2.5/7.6 MB 20.1 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 3.8/7.6 MB 21.8 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 4.8/7.6 MB 22.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 5.7/7.6 MB 21.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 6.6/7.6 MB 21.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.6/7.6 MB 21.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.6/7.6 MB 18.8 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp39-cp39-win_amd64.whl (55 kB)\n",
      "     ---------------------------------------- 0.0/55.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 55.4/55.4 kB ? eta 0:00:00\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp39-cp39-win_amd64.whl (160 kB)\n",
      "     ---------------------------------------- 0.0/160.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 160.2/160.2 kB ? eta 0:00:00\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.39.2-py3-none-any.whl (1.0 MB)\n",
      "     ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "     ---------------------------------------- 1.0/1.0 MB 32.2 MB/s eta 0:00:00\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.4.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "     -------------- ------------------------- 0.9/2.5 MB 29.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 2.3/2.5 MB 29.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 MB 22.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\getab\\anaconda3\\envs\\leapmotionnn\\lib\\site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\getab\\anaconda3\\envs\\leapmotionnn\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\getab\\anaconda3\\envs\\leapmotionnn\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\getab\\anaconda3\\envs\\leapmotionnn\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\getab\\anaconda3\\envs\\leapmotionnn\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.0.7 cycler-0.11.0 fonttools-4.39.2 importlib-resources-5.12.0 kiwisolver-1.4.4 matplotlib-3.7.1 pillow-9.4.0 pyparsing-3.0.9\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _path: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_cm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_confusion_matrix\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\leapmotionNN\\lib\\site-packages\\matplotlib\\pyplot.py:52\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorbar\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\leapmotionNN\\lib\\site-packages\\matplotlib\\colorbar.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, collections, cm, colors, contour, ticker\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmartist\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpatches\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\leapmotionNN\\lib\\site-packages\\matplotlib\\collections.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_api, _path, artist, cbook, cm, colors \u001b[38;5;28;01mas\u001b[39;00m mcolors, _docstring,\n\u001b[0;32m     20\u001b[0m                hatch \u001b[38;5;28;01mas\u001b[39;00m mhatch, lines \u001b[38;5;28;01mas\u001b[39;00m mlines, path \u001b[38;5;28;01mas\u001b[39;00m mpath, transforms)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# \"color\" is excluded; it is a compound setter, and its docstring differs\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# in LineCollection.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _path: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import listdir\n",
    "from os.path import isfile, join, dirname, abspath\n",
    "import warnings\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils_cm import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the length of records (if shorter, we need to add some zero rows)\n",
    "NUMBER_TIMESTEPS = 100\n",
    "# the number of features (from the data)\n",
    "NUMBER_FEATURES = 202\n",
    "# the number of classes/gestures\n",
    "NUMBER_OUTPUTS = 2\n",
    "# you can encode more than 1 but for this example we have binary output (circle/swipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the directory where your data is\n",
    "mypath = './data'\n",
    "\n",
    "# creating a list with all the filenames\n",
    "datafiles = [f for f in listdir('data') if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose data we need\n",
    "columns = ['handPalmPosition_X','handPalmPosition_Y','handPalmPosition_Z',\n",
    "          'pitch', 'roll', 'yaw',\n",
    "          'wristPosition_X', 'wristPosition_Y','wristPosition_Z',\n",
    "          'elbowPosition_X', 'elbowPosition_Y', 'elbowPosition_Z']\n",
    "\n",
    "finger_names = ['Thumb', 'Index', 'Middle', 'Ring', 'Pinky']\n",
    "bone_names = ['Metacarpal', 'Proximal', 'Intermediate', 'Distal']\n",
    "    \n",
    "for finger in finger_names:\n",
    "    columns.append(finger + 'Length')\n",
    "    columns.append(finger + 'Width')\n",
    "\n",
    "for finger in finger_names:\n",
    "    for bone in bone_names:\n",
    "        columns.append(finger + bone + 'Start_X')\n",
    "        columns.append(finger + bone + 'Start_Y')\n",
    "        columns.append(finger + bone + 'Start_Z')\n",
    "        columns.append(finger + bone + 'End_X')\n",
    "        columns.append(finger + bone + 'End_Y')\n",
    "        columns.append(finger + bone + 'End_Z')\n",
    "        columns.append(finger + bone + 'Direction_X') \n",
    "        columns.append(finger + bone + 'Direction_Y') \n",
    "        columns.append(finger + bone + 'Direction_Z')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\1c1.csv\n",
      "size raw = (28, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c10.csv\n",
      "size raw = (23, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c2.csv\n",
      "size raw = (15, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c3.csv\n",
      "size raw = (13, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c4.csv\n",
      "size raw = (18, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c5.csv\n",
      "size raw = (25, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c6.csv\n",
      "size raw = (18, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c7.csv\n",
      "size raw = (24, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c8.csv\n",
      "size raw = (19, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c9.csv\n",
      "size raw = (48, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s1.csv\n",
      "size raw = (33, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s10.csv\n",
      "size raw = (24, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s2.csv\n",
      "size raw = (20, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s3.csv\n",
      "size raw = (22, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s4.csv\n",
      "size raw = (21, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s5.csv\n",
      "size raw = (18, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s6.csv\n",
      "size raw = (18, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s7.csv\n",
      "size raw = (29, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s8.csv\n",
      "size raw = (12, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s9.csv\n",
      "size raw = (19, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\2c1.csv\n",
      "size raw = (27, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c10.csv\n",
      "size raw = (35, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c2.csv\n",
      "size raw = (21, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c3.csv\n",
      "size raw = (24, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c4.csv\n",
      "size raw = (27, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c5.csv\n",
      "size raw = (26, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c6.csv\n",
      "size raw = (26, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c7.csv\n",
      "size raw = (29, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c8.csv\n",
      "size raw = (20, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c9.csv\n",
      "size raw = (25, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s1.csv\n",
      "size raw = (29, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s10.csv\n",
      "size raw = (30, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s2.csv\n",
      "size raw = (27, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s3.csv\n",
      "size raw = (17, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s4.csv\n",
      "size raw = (21, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s5.csv\n",
      "size raw = (25, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s6.csv\n",
      "size raw = (24, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s7.csv\n",
      "size raw = (30, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s8.csv\n",
      "size raw = (29, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s9.csv\n",
      "size raw = (20, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "x = []\n",
    "# Labels\n",
    "y = []\n",
    "\n",
    "for sample in datafiles:\n",
    "    relative_path = 'data\\\\' + sample\n",
    "    tmp = pd.read_csv(relative_path, usecols=columns)\n",
    "    \n",
    "    # Normalize the sample size: LSTM requires all inputs of the same size!\n",
    "    print('{}\\nsize raw = {}'.format(relative_path,tmp.shape))\n",
    "    while tmp.shape[0] < NUMBER_TIMESTEPS:\n",
    "        tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
    "\n",
    "    if tmp.shape[0] > NUMBER_TIMESTEPS:\n",
    "        tmp = tmp.head(100)\n",
    "    print('size normalized = ',tmp.shape)\n",
    "    \n",
    "    tmp_x = tmp[[column for column in list(tmp.columns)]]\n",
    "#                  if column != 'GestureTypeCircle' \n",
    "#                  and column != 'GestureTypeSwipe']]\n",
    "    \n",
    "    # subject 1 --> tmp_y = [1, 0]\n",
    "    tmp_y = [1,  0]\n",
    "    if '2c' in sample or '2s' in sample:\n",
    "        # subject 2 --> tmp_y = [0, 1]\n",
    "        print('file:2')\n",
    "        tmp_y = [0, 1]  \n",
    "        \n",
    "    x.append(tmp_x)\n",
    "    y.append(tmp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "#np.array(y[0].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Each sample requires labels of [1,NUMBER_OUTPUTS] size (not a list)\n",
    "y_new = list()\n",
    "for cur_label in y:\n",
    "    tmp = np.array(cur_label[0])\n",
    "    y_new.append(tmp)\n",
    "y = np.array(y_new)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples = 32\n",
      "Number of test samples = 8\n",
      "There is  <class 'list'>  of  <class 'pandas.core.frame.DataFrame'>\n",
      "The list was turned into <numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "# Set a percentage of test set fraction\n",
    "test_percent = 0.20 # 30%\n",
    "\n",
    "# Divide data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_percent, shuffle=True)\n",
    "len_train = len(X_train)\n",
    "len_test = len(X_test)\n",
    "\n",
    "print ('Number of train samples = {}\\nNumber of test samples = {}'.format(len_train, len_test))\n",
    "print ('There is ',type(X_train),' of ',type(X_train[0]))\n",
    "\n",
    "# Turn list(DataFrame) into numpy.ndarray with [len_train, NUMBER_TIMESTEPS, NUMBER_FEATURES]\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "print('The list was turned into <numpy.ndarray>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train.shape\n",
    "d2_train_dataset = X_train.reshape((nsamples,nx*ny))\n",
    "nsamples, nx, ny = X_test.shape\n",
    "d2_test_dataset = X_test.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Kernel: linear, C: 1, gamma: 0.1 ----\n",
      "Total number of matches: 6\n",
      "Match rate: 0.75\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Generate the confusion matrix\u001b[39;00m\n\u001b[0;32m     18\u001b[0m confusionMatrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mplot_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfusionMatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_subjects\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ENCM 509 lab\\ENCM-509\\project\\utils_cm.py:43\u001b[0m, in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(cm, target_names, title, cmap, normalize, fontsize)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_confusion_matrix\u001b[39m(cm,\n\u001b[0;32m      6\u001b[0m                           target_names,\n\u001b[0;32m      7\u001b[0m                           title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m                           cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m                           normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m                           fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m):\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    given a sklearn confusion matrix (cm), make a nice plot\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "svc_types = ['linear', 'rbf', 'sigmoid', 'poly']\n",
    "C_list = [1,10,100]\n",
    "gamma_list = [0.1, 0.01, 0.001]\n",
    "n_subjects = 2\n",
    "for kernel in svc_types:\n",
    "    for C in C_list:\n",
    "        for gamma in gamma_list:\n",
    "            print(f\"----Kernel: {kernel}, C: {C}, gamma: {gamma} ----\")\n",
    "            clf = SVC(kernel=kernel)\n",
    "            clf.fit(d2_train_dataset, y_train)\n",
    "            y_pred = clf.predict(d2_test_dataset)\n",
    "            matches = (y_pred == y_test)\n",
    "            print('Total number of matches: %d' % (matches.sum()))\n",
    "\n",
    "            match_rate = matches.sum() / float(len(matches))\n",
    "            print('Match rate: %.2f' % (match_rate))\n",
    "            # Generate the confusion matrix\n",
    "            confusionMatrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "            plot_confusion_matrix(cm=confusionMatrix,\n",
    "            target_names = [i for i in range(1, n_subjects+1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
