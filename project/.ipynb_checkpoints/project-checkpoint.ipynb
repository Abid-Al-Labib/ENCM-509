{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _imaging: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils_cm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_confusion_matrix\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# warnings.simplefilter(action='ignore', category=FutureWarning)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\leapmotionNN\\lib\\site-packages\\matplotlib\\__init__.py:131\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\leapmotionNN\\lib\\site-packages\\matplotlib\\rcsetup.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\leapmotionNN\\lib\\site-packages\\matplotlib\\colors.py:51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumbers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Number\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mPngImagePlugin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PngInfo\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\leapmotionNN\\lib\\site-packages\\PIL\\Image.py:103\u001b[0m\n\u001b[0;32m     94\u001b[0m MAX_IMAGE_PIXELS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;66;03m# If the _imaging C module is not present, Pillow will not load.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;66;03m# Note that other modules should not refer to _imaging directly;\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# import Image and use the Image.core variable instead.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# Also note that Image.core is not a publicly documented interface,\u001b[39;00m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# and should be considered private and subject to change.\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _imaging \u001b[38;5;28;01mas\u001b[39;00m core\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m __version__ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(core, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    106\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe _imaging extension was built for another version of Pillow or PIL:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCore version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mgetattr\u001b[39m(core,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPILLOW_VERSION\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPillow version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         )\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing _imaging: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import listdir\n",
    "from os.path import isfile, join, dirname, abspath\n",
    "import warnings\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from utils_cm import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the length of records (if shorter, we need to add some zero rows)\n",
    "NUMBER_TIMESTEPS = 100\n",
    "# the number of features (from the data)\n",
    "NUMBER_FEATURES = 202\n",
    "# the number of classes/gestures\n",
    "NUMBER_OUTPUTS = 2\n",
    "# you can encode more than 1 but for this example we have binary output (circle/swipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the directory where your data is\n",
    "mypath = './data'\n",
    "\n",
    "# creating a list with all the filenames\n",
    "datafiles = [f for f in listdir('data') if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose data we need\n",
    "columns = ['handPalmPosition_X','handPalmPosition_Y','handPalmPosition_Z',\n",
    "          'pitch', 'roll', 'yaw',\n",
    "          'wristPosition_X', 'wristPosition_Y','wristPosition_Z',\n",
    "          'elbowPosition_X', 'elbowPosition_Y', 'elbowPosition_Z']\n",
    "\n",
    "finger_names = ['Thumb', 'Index', 'Middle', 'Ring', 'Pinky']\n",
    "bone_names = ['Metacarpal', 'Proximal', 'Intermediate', 'Distal']\n",
    "    \n",
    "for finger in finger_names:\n",
    "    columns.append(finger + 'Length')\n",
    "    columns.append(finger + 'Width')\n",
    "\n",
    "for finger in finger_names:\n",
    "    for bone in bone_names:\n",
    "        columns.append(finger + bone + 'Start_X')\n",
    "        columns.append(finger + bone + 'Start_Y')\n",
    "        columns.append(finger + bone + 'Start_Z')\n",
    "        columns.append(finger + bone + 'End_X')\n",
    "        columns.append(finger + bone + 'End_Y')\n",
    "        columns.append(finger + bone + 'End_Z')\n",
    "        columns.append(finger + bone + 'Direction_X') \n",
    "        columns.append(finger + bone + 'Direction_Y') \n",
    "        columns.append(finger + bone + 'Direction_Z')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\1c1.csv\n",
      "size raw = (28, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c10.csv\n",
      "size raw = (23, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c2.csv\n",
      "size raw = (15, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c3.csv\n",
      "size raw = (13, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c4.csv\n",
      "size raw = (18, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c5.csv\n",
      "size raw = (25, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c6.csv\n",
      "size raw = (18, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c7.csv\n",
      "size raw = (24, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c8.csv\n",
      "size raw = (19, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1c9.csv\n",
      "size raw = (48, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s1.csv\n",
      "size raw = (33, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s10.csv\n",
      "size raw = (24, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s2.csv\n",
      "size raw = (20, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s3.csv\n",
      "size raw = (22, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s4.csv\n",
      "size raw = (21, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s5.csv\n",
      "size raw = (18, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s6.csv\n",
      "size raw = (18, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s7.csv\n",
      "size raw = (29, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s8.csv\n",
      "size raw = (12, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\1s9.csv\n",
      "size raw = (19, 202)\n",
      "size normalized =  (100, 202)\n",
      "data\\2c1.csv\n",
      "size raw = (27, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c10.csv\n",
      "size raw = (35, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c2.csv\n",
      "size raw = (21, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c3.csv\n",
      "size raw = (24, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c4.csv\n",
      "size raw = (27, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c5.csv\n",
      "size raw = (26, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c6.csv\n",
      "size raw = (26, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c7.csv\n",
      "size raw = (29, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c8.csv\n",
      "size raw = (20, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2c9.csv\n",
      "size raw = (25, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s1.csv\n",
      "size raw = (29, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s10.csv\n",
      "size raw = (30, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s2.csv\n",
      "size raw = (27, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s3.csv\n",
      "size raw = (17, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s4.csv\n",
      "size raw = (21, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s5.csv\n",
      "size raw = (25, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s6.csv\n",
      "size raw = (24, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s7.csv\n",
      "size raw = (30, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s8.csv\n",
      "size raw = (29, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n",
      "data\\2s9.csv\n",
      "size raw = (20, 202)\n",
      "size normalized =  (100, 202)\n",
      "file:2\n"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "x = []\n",
    "# Labels\n",
    "y = []\n",
    "\n",
    "for sample in datafiles:\n",
    "    relative_path = 'data\\\\' + sample\n",
    "    tmp = pd.read_csv(relative_path, usecols=columns)\n",
    "    \n",
    "    # Normalize the sample size: LSTM requires all inputs of the same size!\n",
    "    print('{}\\nsize raw = {}'.format(relative_path,tmp.shape))\n",
    "    while tmp.shape[0] < NUMBER_TIMESTEPS:\n",
    "        tmp = tmp.append(pd.Series(0, index=tmp.columns), ignore_index=True)\n",
    "\n",
    "    if tmp.shape[0] > NUMBER_TIMESTEPS:\n",
    "        tmp = tmp.head(100)\n",
    "    print('size normalized = ',tmp.shape)\n",
    "    \n",
    "    tmp_x = tmp[[column for column in list(tmp.columns)]]\n",
    "#                  if column != 'GestureTypeCircle' \n",
    "#                  and column != 'GestureTypeSwipe']]\n",
    "    \n",
    "    # subject 1 --> tmp_y = [1, 0]\n",
    "    tmp_y = [1,  0]\n",
    "    if '2c' in sample or '2s' in sample:\n",
    "        # subject 2 --> tmp_y = [0, 1]\n",
    "        print('file:2')\n",
    "        tmp_y = [0, 1]  \n",
    "        \n",
    "    x.append(tmp_x)\n",
    "    y.append(tmp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "#np.array(y[0].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Each sample requires labels of [1,NUMBER_OUTPUTS] size (not a list)\n",
    "y_new = list()\n",
    "for cur_label in y:\n",
    "    tmp = np.array(cur_label[0])\n",
    "    y_new.append(tmp)\n",
    "y = np.array(y_new)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples = 32\n",
      "Number of test samples = 8\n",
      "There is  <class 'list'>  of  <class 'pandas.core.frame.DataFrame'>\n",
      "The list was turned into <numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "# Set a percentage of test set fraction\n",
    "test_percent = 0.20 # 30%\n",
    "\n",
    "# Divide data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_percent, shuffle=True)\n",
    "len_train = len(X_train)\n",
    "len_test = len(X_test)\n",
    "\n",
    "print ('Number of train samples = {}\\nNumber of test samples = {}'.format(len_train, len_test))\n",
    "print ('There is ',type(X_train),' of ',type(X_train[0]))\n",
    "\n",
    "# Turn list(DataFrame) into numpy.ndarray with [len_train, NUMBER_TIMESTEPS, NUMBER_FEATURES]\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "print('The list was turned into <numpy.ndarray>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train.shape\n",
    "d2_train_dataset = X_train.reshape((nsamples,nx*ny))\n",
    "nsamples, nx, ny = X_test.shape\n",
    "d2_test_dataset = X_test.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Kernel: linear, C: 1, gamma: 0.1 ----\n",
      "Total number of matches: 6\n",
      "Match rate: 0.75\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Generate the confusion matrix\u001b[39;00m\n\u001b[0;32m     18\u001b[0m confusionMatrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mplot_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfusionMatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_subjects\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\ENCM 509 lab\\ENCM-509\\project\\utils_cm.py:43\u001b[0m, in \u001b[0;36mplot_confusion_matrix\u001b[1;34m(cm, target_names, title, cmap, normalize, fontsize)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_confusion_matrix\u001b[39m(cm,\n\u001b[0;32m      6\u001b[0m                           target_names,\n\u001b[0;32m      7\u001b[0m                           title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m                           cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m                           normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m                           fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m):\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    given a sklearn confusion matrix (cm), make a nice plot\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "svc_types = ['linear', 'rbf', 'sigmoid', 'poly']\n",
    "C_list = [1,10,100]\n",
    "gamma_list = [0.1, 0.01, 0.001]\n",
    "n_subjects = 2\n",
    "for kernel in svc_types:\n",
    "    for C in C_list:\n",
    "        for gamma in gamma_list:\n",
    "            print(f\"----Kernel: {kernel}, C: {C}, gamma: {gamma} ----\")\n",
    "            clf = SVC(kernel=kernel)\n",
    "            clf.fit(d2_train_dataset, y_train)\n",
    "            y_pred = clf.predict(d2_test_dataset)\n",
    "            matches = (y_pred == y_test)\n",
    "            print('Total number of matches: %d' % (matches.sum()))\n",
    "\n",
    "            match_rate = matches.sum() / float(len(matches))\n",
    "            print('Match rate: %.2f' % (match_rate))\n",
    "            # Generate the confusion matrix\n",
    "            confusionMatrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "            plot_confusion_matrix(cm=confusionMatrix,\n",
    "            target_names = [i for i in range(1, n_subjects+1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
